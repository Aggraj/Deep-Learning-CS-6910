{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBM_Contrastive_Divergence.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+EIoDkYmd1drlTFK9jBju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aggraj/Deep-Learning-CS-6910/blob/main/RBM_Contrastive_Divergence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXKghDepGCtW"
      },
      "source": [
        "Import WandB "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_77DO3ZE6uJ"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuyV1uN1FEr9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.datasets import mnist\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuRh8bzrGI1_"
      },
      "source": [
        "**Read the Fashion MNIST data set, divide the data set as train and validation. There are 10 class in the data set. Initialize all the variables e.g : number of hidden layer size, number of class etc**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6a4hxqmFHW5"
      },
      "source": [
        "# load the Fashion MNIST data set\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "class_type = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] \n",
        "\n",
        "Project='ASSIGNMENT 4'\n",
        "\n",
        "\n",
        "# Split the data set and assign the data values depending on thresholding\n",
        "X_train = np.array(x_train.reshape(x_train.shape[0], 784,1))         \n",
        "X_test  = np.array(x_test.reshape(x_test.shape[0], 784,1))           \n",
        "X_train = (X_train > 126) * 1                                        \n",
        "X_test  = (X_test > 126) * 1                                         \n",
        "X_val = X_train[-15000:]                                             \n",
        "X_train = X_train[0:45000]                                           \n",
        "\n",
        "Y_train = np.zeros([len(y_train),10,1])\n",
        "Y_test = np.zeros([len(y_test),10,1])\n",
        "\n",
        "for i in range(len(y_train)):                                       \n",
        "  y = np.zeros([10, 1])\n",
        "  y[y_train[i]] = 1.0\n",
        "  Y_train[i] = y\n",
        "\n",
        "for i in range(len(y_test)):                                         \n",
        "  y = np.zeros([10, 1])\n",
        "  y[y_test[i]] = 1.0\n",
        "  Y_test[i] = y                                                      \n",
        "\n",
        "Y_val = Y_train[-15000:]                                             \n",
        "Y_train = Y_train[0:45000]        \n",
        "\n",
        "\n",
        "n_vis = X_train.shape[1]                                         \n",
        "n_train = X_train.shape[0]                                  \n",
        "n_val = X_val.shape[0]                                      \n",
        "n_test = X_test.shape[0]                                    \n",
        "n_hidden = 64                 \n",
        "n_class = 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12jxvCP0GuFV"
      },
      "source": [
        "**Define activation functions, Initalize Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCJPhD_cE4Up"
      },
      "source": [
        "def sigmoid(x) :                                                                              \n",
        "\t\n",
        "  return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def softmax(x):                                                                               \n",
        "  return np.exp(x) / np.sum(np.exp(x))  \n",
        "\n",
        "\n",
        "def RBM_init_params() :                                                                        \n",
        "\t\n",
        "  RBM_params = {}\n",
        "  RBM_params[\"W\"] = np.random.randn(n_hidden, n_vis)*np.sqrt(6./(n_vis + n_hidden))   \n",
        "  RBM_params[\"h_b\"] = np.zeros((n_hidden,1),dtype=np.float64)                                                     \n",
        "  RBM_params[\"v_b\"] = np.zeros((n_vis,1),dtype=np.float64)\n",
        "\n",
        "  return RBM_params\n",
        "\n",
        "def Class_params_init() :                                                                 \n",
        "\n",
        "  class_params = {}\n",
        "  class_params[\"W\"] = np.random.randn(n_class, n_hidden)*np.sqrt(6./(n_class + n_hidden))       \n",
        "  class_params[\"b\"] = np.zeros((n_class,1),dtype=np.float64)\n",
        "\n",
        "  return class_params\n",
        "\n",
        "\n",
        "def hidden_representation(x,parameters) :                                                               \n",
        "   \n",
        "    W = parameters[\"W\"]\n",
        "    h_b = parameters[\"h_b\"]\n",
        "    hidden_prob = sigmoid(np.dot(W,x)+h_b)\n",
        "    hidden_rep = np.random.binomial(1,hidden_prob)\n",
        "    \n",
        "    return hidden_rep                                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKvBznI8HF8U"
      },
      "source": [
        "# **Train the RBM model using Contrastive Divergence and Train the classifer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrBm0gAJG7ua"
      },
      "source": [
        "def Train_RBM(X_train,parameters,k,learning_rate) :                       # Function to train the RBM\n",
        "\t\n",
        "  W = parameters[\"W\"]\n",
        "  h_b = parameters[\"h_b\"]\n",
        "  v_b = parameters[\"v_b\"]\n",
        "  \n",
        "  \n",
        "  for i in range(n_train) :\n",
        "      v_s = X_train[i]\n",
        "      v_in   = X_train[i]\n",
        "\n",
        "      for t in range(k) :                                                               # Markov Chain \n",
        "         p_h_g_v = sigmoid(np.dot(W,v_s)+h_b)                                  \n",
        "         h_s = np.random.binomial(1,p_h_g_v)                                      \n",
        "         p_v_g_h = sigmoid(np.dot(np.transpose(W),h_s)+v_b)                    \n",
        "         v_s = np.random.binomial(1,p_v_g_h)                                      # Convert to 0's and 1's using binomial distribution \n",
        "\n",
        "      # Update Rule\n",
        "      W = W + learning_rate*(np.dot(sigmoid(np.dot(W,v_in)+h_b),np.transpose(v_in)) - np.dot(sigmoid(np.dot(W,v_s)+h_b),np.transpose(v_s)))\n",
        "      v_b = v_b + learning_rate*(v_in-v_s)\n",
        "      h_b = h_b + learning_rate*(sigmoid(np.dot(W,v_in)+h_b) - sigmoid(np.dot(W,v_s)+h_b))\n",
        "\n",
        "  parameters[\"W\"] = W\n",
        "  parameters[\"h_b\"] = h_b\n",
        "  parameters[\"v_b\"] = v_b\n",
        "\n",
        "  return parameters\n",
        "\n",
        "def Train_class(X,Y,RBM_params,param_cls,eph_c,learning_rate)  :                                  \n",
        "    \n",
        "    W = param_cls[\"W\"]\n",
        "    b = param_cls[\"b\"]\n",
        "    \n",
        "    for epoch in range(eph_c) :\n",
        "      for i in range(n_val) :\n",
        "         # feed forward\n",
        "         hidden_rep = hidden_representation(X[i],RBM_params)                                         \n",
        "         previous_out = np.dot(W,hidden_rep)+b\n",
        "         y_hat = softmax(previous_out)\n",
        "         # backpropogate\n",
        "         dW = np.dot(-(Y[i]-y_hat),np.transpose(hidden_rep))\n",
        "         db = -(Y[i]-y_hat)\n",
        "         # Update Classifier weights\n",
        "         W = W - learning_rate*dW\n",
        "         b = b - learning_rate*db\n",
        "\n",
        "    param_cls[\"W\"] = W\n",
        "    param_cls[\"b\"] = b \n",
        "    \n",
        "    return param_cls   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEe6Wj8vHUi4"
      },
      "source": [
        "# **RBM classifier**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly9KcqZmHUAh"
      },
      "source": [
        "\n",
        "def RBM_clsfier(X_train,Y_train,X_val,Y_val,X_test,Y_test,epochs_RBM,eph_c,k,n_hidden,learning_rate) :\n",
        "  param_cls  = Class_params_init() \n",
        "  RBM_params = RBM_init_params()\n",
        "\n",
        "  for j in range(epochs_RBM) :\n",
        "     RBM_params = Train_RBM(X_train,RBM_params,k,learning_rate)                             \n",
        "     param_cls = Train_class(X_val,Y_val,RBM_params,param_cls,eph_c,learning_rate)               \n",
        "     \n",
        "     accuracy = 0.0\n",
        "     loss = 0.0 \n",
        "     # Evaluate accuracy and loss over test data\n",
        "     for i in range(n_test) :\n",
        "        h = hidden_representation(X_test[i],RBM_params)\n",
        "        y_hat = softmax(np.dot(param_cls[\"W\"],h)+param_cls[\"b\"])\n",
        "\n",
        "        if y_hat.argmax()==Y_test[i].argmax():\n",
        "            accuracy = accuracy + 1\n",
        "        loss = loss + -1*np.sum(np.multiply(y,np.log(y_hat)))\n",
        "\n",
        "     accuracy = accuracy/n_test\n",
        "     loss = loss/n_test \n",
        "     print(\"Epoch :\" + str(j)+\" \"+ str(accuracy)+\" \"+str(loss))\n",
        "     wandb.log({\"Accuracy\":accuracy,\"Loss\":loss,\"Epoch\":j})\n",
        "  return RBM_params,param_cls, accuracy, loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u17ldJ3EFjWL"
      },
      "source": [
        "def train():\n",
        "  hyperparameter_defaults=dict(\n",
        "        epochs_RBM = 5,\n",
        "        eph_c = 3,\n",
        "        k = 40,\n",
        "        n_hidden = 80,\n",
        "        learning_rate = 0.1                                                                    \n",
        "        )\n",
        "\n",
        "  wandb.init(config=hyperparameter_defaults)\n",
        "\n",
        "  config=wandb.config\n",
        "  RBM_params,param_cls,accuracy,loss = RBM_clsfier(X_train,Y_train,X_val,Y_val,X_test,Y_test,config.epochs_RBM,config.eph_c,config.k,config.n_hidden,config.learning_rate)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opqv-F8kHeNJ"
      },
      "source": [
        "**Sweep over all the hy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip8XSmDyFj--"
      },
      "source": [
        "def sweeper(sweep_config,Project):\n",
        "  sweep_id=wandb.sweep(sweep_config,project=Project,entity='chaxin',)\n",
        "  sweep_id = \"nhvl1lun\"\n",
        "  wandb.agent(sweep_id,train,project=Project,entity='chaxin',)\n",
        "\n",
        "\n",
        "#sweep dictionary\n",
        "sweep_config={\n",
        "    'method':'bayes',\n",
        "    'metric':{\n",
        "        'name':'accuracy',\n",
        "        'goal':'maximize'},\n",
        "\n",
        "}\n",
        "\n",
        "parameters_sweep={\n",
        "    \n",
        "    'epochs_RBM':{\n",
        "      'values':[7]  \n",
        "    },\n",
        "    'eph_c':{\n",
        "        'values':[1]\n",
        "    },\n",
        "    'k':{\n",
        "        'values':[1,5,10,15,20]\n",
        "    },\n",
        "    'n_hidden':{\n",
        "        'values':[64,128,256]\n",
        "    },\n",
        "    'learning_rate':{\n",
        "        'values':[0.01]\n",
        "    }\n",
        "    \n",
        "}\n",
        "\n",
        "sweep_config['parameters']=parameters_sweep  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2QZbmWqFwnv"
      },
      "source": [
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_nOxq01Fx5w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}